{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3 - Deep Domain Adaptation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cpeluso/HW3-Deep-Domain-Adaptation/blob/master/HW3_Deep_Domain_Adaptation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install 'torch==1.3.1'\n",
        "# !pip3 install 'torchvision==0.5.0'\n",
        "# !pip3 install 'Pillow-SIMD'\n",
        "# !pip3 install 'tqdm'\n",
        "\n",
        "!rm -rf \"./DANN\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2f8c035e-27f5-4538-f05e-5ba2d1a8c32f"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import output\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments, Define Data Preprocessing, Prepare Datasets, DataLoader and Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "ad360339-c569-4842-f5ec-7bdc01b13d06"
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 7 \n",
        "NUM_DOMAINS = 2\n",
        "\n",
        "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 1e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "\n",
        "# Define transforms for the test phase\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])\n",
        "\n",
        "# Clone github repository with data\n",
        "if not os.path.isdir('./PACS'):\n",
        "  !git clone https://github.com/MachineLearning2020/Homework3-PACS.git\n",
        "  !mv 'Homework3-PACS' 'PACS'\n",
        "\n",
        "DATA_DIR = [\n",
        "  \"PACS/PACS/art_painting\",\n",
        "  \"PACS/PACS/cartoon\",\n",
        "  \"PACS/PACS/photo\",\n",
        "  \"PACS/PACS/sketch\"\n",
        "]\n",
        "\n",
        "train_dataset = ImageFolder(DATA_DIR[2], transform = train_transform) # Photo\n",
        "test_dataset = ImageFolder(DATA_DIR[0], transform = test_transform) # Art Painting\n",
        "\n",
        "cartoonDataset = ImageFolder(DATA_DIR[1])\n",
        "sketchDataset = ImageFolder(DATA_DIR[3])\n",
        "\n",
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "dataloader_source = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "dataloader_target = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "if not os.path.isdir('./DANN'):\n",
        "  !git clone https://github.com/cpeluso/HW3-Deep-Domain-Adaptation.git\n",
        "  !mv 'HW3-Deep-Domain-Adaptation' 'DANN'\n",
        "\n",
        "from DANN.DANN import RandomNetworkWithReverseGrad\n",
        "\n",
        "dann = RandomNetworkWithReverseGrad.alexnet_dann(pretrained=True)\n",
        "\n",
        "for classifier_layer, dann_classifier_layer in zip(dann.classifier, dann.dann_classifier):\n",
        "  if type(classifier_layer) is torch.nn.modules.linear.Linear:\n",
        "    dann_classifier_layer.weight.data = classifier_layer.weight.data\n",
        "    dann_classifier_layer.bias.data = classifier_layer.bias.data\n",
        "\n",
        "dann.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "dann.dann_classifier[6] = nn.Linear(4096, NUM_DOMAINS)\n",
        "\n",
        "output.clear()\n",
        "\n",
        "dann"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomNetworkWithReverseGrad(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=7, bias=True)\n",
              "  )\n",
              "  (dann_classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "loss_classifier = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "loss_discriminator = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose parameters to optimize\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\n",
        "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n",
        "parameters_to_optimize = dann.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "target_set = iter(dataloader_target)\n",
        "\n",
        "def sample_target(step, n_batches):\n",
        "    global target_set\n",
        "    if step % n_batches == 0:\n",
        "        target_set = iter(dataloader_target)\n",
        "    return target_set.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJdFgbFXeBVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_losses(classifier_losses, discriminator_source_losses, discriminator_target_losses, titles):\n",
        "  classifier_loss_df = pd.DataFrame(classifier_losses)\n",
        "  classifier_loss_df = classifier_loss_df.astype(float)\n",
        "  classifier_loss_df.columns=['Epoch','Loss']\n",
        "\n",
        "  discriminator_source_loss_df = pd.DataFrame(discriminator_source_losses)\n",
        "  discriminator_source_loss_df = discriminator_source_loss_df.astype(float)\n",
        "  discriminator_source_loss_df.columns=['Epoch','Loss']\n",
        "\n",
        "  discriminator_target_loss_df = pd.DataFrame(discriminator_target_losses)\n",
        "  discriminator_target_loss_df = discriminator_target_loss_df.astype(float)\n",
        "  discriminator_target_loss_df.columns=['Epoch','Loss']\n",
        "\n",
        "  plt.figure()  \n",
        "  sns.set(style = \"whitegrid\")\n",
        "  fig, ax = plt.subplots(figsize=(20, 6))\n",
        "\n",
        "  sns.lineplot(x='Epoch',y='Loss',data=classifier_loss_df, markers=True, dashes=False,  ax = ax)\n",
        "  sns.lineplot(x='Epoch',y='Loss',data=discriminator_source_loss_df, markers=True, dashes=False,  ax = ax)\n",
        "  sns.lineplot(x='Epoch',y='Loss',data=discriminator_target_loss_df, markers=True, dashes=False,  ax = ax)\n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnyvSQ0-zxU5",
        "colab_type": "code",
        "outputId": "9545771b-0f1e-49a7-e516-3f67fbcdeb02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "discriminator_source_labels = torch.zeros(BATCH_SIZE, dtype=torch.long).to(DEVICE) # Discriminator label to Photo\n",
        "discriminator_target_labels = torch.ones(BATCH_SIZE, dtype=torch.long).to(DEVICE) # Discriminator label to Art Painting\n",
        "discriminator_labels = torch.cat([discriminator_source_labels, discriminator_target_labels], dim=0)\n",
        "\n",
        "LAMBDA=0.5\n",
        "already_recomputed_short_discriminator_target_labels = False\n",
        "\n",
        "dann = dann.to(DEVICE) \n",
        "cudnn.benchmark\n",
        "current_step = 0\n",
        "\n",
        "classifier_losses = []\n",
        "discriminator_source_losses = []\n",
        "discriminator_target_losses = []\n",
        "\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  \n",
        "  print(\"Epoch \" + str(epoch+1))\n",
        "  \n",
        "  for index, (source_images, labels) in enumerate(dataloader_source):\n",
        "\n",
        "    dann.train()\n",
        "\n",
        "    target_images, target_set = sample_target(current_step, BATCH_SIZE)\n",
        "\n",
        "    source = source_images.to(DEVICE)\n",
        "    target = target_images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    classifier_output = dann(source)\n",
        "    classifier_loss = loss_classifier(classifier_output, labels)\n",
        "    classifier_loss.backward()\n",
        "\n",
        "    discriminator_output_source = dann(source, LAMBDA)\n",
        "    discriminator_loss_source = loss_discriminator(discriminator_output_source, discriminator_source_labels)\n",
        "    discriminator_loss_source.backward()\n",
        "\n",
        "    discriminator_output_target = dann(target, LAMBDA)\n",
        "\n",
        "    if BATCH_SIZE != len(discriminator_output_target):\n",
        "\n",
        "      print(\"Im in\")\n",
        "\n",
        "      short_discriminator_target_labels = torch.zeros(len(discriminator_output_target), dtype = torch.long).to(DEVICE) if short_discriminator_target_labels is None else short_discriminator_target_labels\n",
        "    \n",
        "      discriminator_loss_target = loss_discriminator(discriminator_output_target, short_discriminator_target_labels)\n",
        "   \n",
        "    else:\n",
        "      \n",
        "      discriminator_loss_target = loss_discriminator(discriminator_output_target, discriminator_target_labels)\n",
        "\n",
        "    discriminator_loss_target.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  scheduler.step() \n",
        "  \n",
        "  print(\"Classifier loss: \", str(classifier_loss.item()))\n",
        "  print(\"Discriminator (source) loss: \", str(discriminator_loss_source.item()))\n",
        "  print(\"Discriminator (target) loss: \", str(discriminator_loss_target.item()))\n",
        "\n",
        "  classifier_losses.append( (epoch + 1, classifier_loss.item()) )\n",
        "  discriminator_source_losses.append( (epoch + 1, discriminator_loss_source.item()) )\n",
        "  discriminator_target_losses.append( (epoch + 1, discriminator_loss_target.item()) )\n",
        "\n",
        "output.clear()\n",
        "plot_losses(classifier_losses, discriminator_source_losses, discriminator_target_losses, titles = [])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}